---
layout: post
title: Chaos monkey for docker
date: 2018-02-16 23:47:25.000000000 -08:00
type: post
parent_id: '0'
published: true
password: ''
status: publish
categories:
- Code
tags:
- fault tolerance
- ruby
- service oriented architecture
meta:
  _wpcom_is_markdown: '1'
  _edit_last: '1'
  _syntaxhighlighter_encoded: '1'
  _su_rich_snippet_type: none
  _jetpack_related_posts_cache: a:1:{s:32:"8f6677c9d6b0f903e98ad32ec61f8deb";a:2:{s:7:"expires";i:1561472557;s:7:"payload";a:3:{i:0;a:1:{s:2:"id";i:4699;}i:1;a:1:{s:2:"id";i:4673;}i:2;a:1:{s:2:"id";i:5000;}}}}
  _wpas_done_all: '1'
  _jetpack_dont_email_post_to_subs: '1'
author:
  login: akropp
  email: akropp@gmail.com
  display_name: akropp
  first_name: ''
  last_name: ''
permalink: "/2018/02/16/chaos-monkey-docker/"
---
<p>I work at a mostly AWS shop, and while we still have services on raw EC2, nearly all of our new development is on Amazon ECS in docker.  I like docker because it provides a unified unit of operation (a container) that makes it easy to build shared tooling regardless of language/application.  It also lets you reproduce your applications local in the same environment they run remote, as well as starting fast and deploying fast.</p>
<p>However, many services run on a shared ECS node in a cluster, and so while things like Chaos Monkey may run around turning nodes off it'd be nice to have a little less of an impact during working hours while still being able to stress recovery and our alerting.</p>
<p>This is actually pretty easy though with a little docker container we call <code>The Beast</code>.  All the beast does is run on a ECS Scheduled event every 15-30 minutes from 10am - 3pm PST (we have teams east and west coasts) and the beast kills a random container from whatever cluster node its on.  It doesn't do a lot of damage, but it does test your fault tolerance.</p>
<p>Here's The Beast:</p>
<p>[ruby]<br />
#!/usr/bin/env ruby</p>
<p>require 'json'<br />
require 'pp'</p>
<p>class Hash<br />
  def extract_subhash(*extract)<br />
    h2 = self.select{|key, value| extract.include?(key) }<br />
    self.delete_if {|key, value| extract.include?(key) }<br />
    h2<br />
  end<br />
end</p>
<p>puts &quot;UNLEASH THE BEAST!&quot;</p>
<p>ignore_image_regex = ENV[&quot;IGNORED_REGEX&quot;]</p>
<p>raw = &quot;[#{`docker ps --format '{{json .}}'`.lines.join(',')}]&quot;</p>
<p>running_services = JSON.parse(raw).map { |val| val.extract_subhash(&quot;ID&quot;, &quot;Image&quot;)}</p>
<p>puts running_services</p>
<p>puts &quot;Ignoring regex #{ignore_image_regex}&quot;</p>
<p>if ignore_image_regex &amp;&amp; ignore_image_regex.length &gt; 0<br />
  running_services.delete_if {|value|<br />
    /#{ignore_image_regex}/ === value[&quot;Image&quot;]<br />
  }<br />
end</p>
<p>if !running_services || running_services.length == 0<br />
  puts &quot;No services to kill&quot;</p>
<p>  Process.exit(0)<br />
end</p>
<p>puts &quot;Bag of services to kill: &quot;</p>
<p>to_kill = running_services.sample</p>
<p>puts &quot;Killing #{pp to_kill}&quot;</p>
<p>`docker kill #{to_kill[&quot;ID&quot;]}`</p>
<p>prng = Random.new</p>
<p>quips = [<br />
    &quot;Dont fear the reaper&quot;,<br />
    &quot;BEAST MODE&quot;,<br />
    &quot;You been rubby'd&quot;,<br />
    &quot;Pager doody&quot;<br />
]</p>
<p>puts &quot;#{quips[prng.rand(0..quips.length-1)]}&quot;<br />
[/ruby]</p>
<p>Beast supports a regex of ignored images (so critical images like the ecs_agent and itself) can be marked as ignore.  This can also be used to update the beast to allow it to ignore services temporarily/etc.</p>
<p>We deploy The Beast with terraform, the general task definition looks like:</p>
<p>[code]<br />
[<br />
  {<br />
    &quot;name&quot;: &quot;the-beast&quot;,<br />
    &quot;image&quot;: &quot;${image}:${version}&quot;,<br />
    &quot;cpu&quot;: 10,<br />
    &quot;memory&quot;: 50,<br />
    &quot;essential&quot;: true,<br />
    &quot;logConfiguration&quot;: {<br />
        &quot;logDriver&quot;: &quot;awslogs&quot;,<br />
        &quot;options&quot;: {<br />
          &quot;awslogs-group&quot;: &quot;${log_group}&quot;,<br />
          &quot;awslogs-region&quot;: &quot;${region}&quot;,<br />
          &quot;awslogs-stream-prefix&quot;: &quot;the-beast&quot;<br />
        }<br />
    },<br />
    &quot;environment&quot;: [<br />
        {<br />
          &quot;name&quot;: &quot;IGNORED_REGEX&quot;, &quot;value&quot;: &quot;.*ecs_agent.*|.*the-beast.*&quot;<br />
        }<br />
    ],<br />
    &quot;mountPoints&quot;: [<br />
        { &quot;sourceVolume&quot;: &quot;docker-socket&quot;, &quot;containerPath&quot;: &quot;/var/run/docker.sock&quot;, &quot;readOnly&quot;: true }<br />
    ]<br />
  }<br />
]<br />
[/code]</p>
<p>And the terraform:</p>
<p>[code]<br />
resource &quot;aws_ecs_task_definition&quot; &quot;beast_rule&quot; {<br />
  family = &quot;beast-service&quot;<br />
  container_definitions = &quot;${data.template_file.task_definition.rendered}&quot;</p>
<p>  volume {<br />
    name = &quot;docker-socket&quot;<br />
    host_path = &quot;/var/run/docker.sock&quot;<br />
  }<br />
}</p>
<p>data &quot;template_file&quot; &quot;task_definition&quot; {<br />
  template = &quot;${file(&quot;${path.module}/files/task-definition.tpl&quot;)}&quot;</p>
<p>  vars {<br />
    version = &quot;${var.beast-service[&quot;version&quot;]}&quot;<br />
    region = &quot;${var.region}&quot;<br />
    image = &quot;${data.terraform_remote_state.remote_env_state.docker_namespace}/the-beast&quot;<br />
    log_group = &quot;${var.log-group}&quot;<br />
  }<br />
}</p>
<p>resource &quot;aws_cloudwatch_event_target&quot; &quot;beast_scheduled_job_target&quot; {<br />
  target_id = &quot;${aws_ecs_task_definition.beast_rule.family}&quot;<br />
  rule = &quot;${aws_cloudwatch_event_rule.beast_scheduled_job.name}&quot;<br />
  arn = &quot;${data.aws_ecs_cluster.default_cluster.id}&quot;<br />
  role_arn = &quot;${data.aws_iam_role.ecs_service_role.arn}&quot;<br />
  ecs_target {<br />
    task_count = 1<br />
    task_definition_arn = &quot;${aws_ecs_task_definition.beast_rule.arn}&quot;<br />
  }<br />
}</p>
<p>resource &quot;aws_cloudwatch_event_rule&quot; &quot;beast_scheduled_job&quot; {<br />
  name = &quot;${aws_ecs_task_definition.beast_rule.family}&quot;<br />
  description = &quot;Beast kills a container every 30 minutes from 10AM to 3PM PST Mon-Thu&quot;<br />
  schedule_expression = &quot;cron(0/30 18-23 ? * MON-THU *)&quot;<br />
  is_enabled = false<br />
}</p>
<p>resource &quot;aws_cloudwatch_log_group&quot; &quot;beast_log_group&quot; {<br />
  name = &quot;${var.log-group}&quot;<br />
}<br />
[/code]</p>
<p>We can log to cloudwatch and correlate back information if a service was killed by the best as well.  It's important to note that you need to mount the docker socket for beast to work, since it needs docker to run.  A sample dockerfile looks like:</p>
<p>[code]<br />
FROM ubuntu:xenial</p>
<p>RUN apt-get update &amp;&amp; apt-get install -y ruby-full docker.io build-essential</p>
<p>RUN gem install json</p>
<p>ADD beast.rb /app/beast.rb</p>
<p>RUN chmod +x /app/beast.rb</p>
<p>ENTRYPOINT &quot;/app/beast.rb&quot;<br />
[/code]</p>
<p>It's bare bones, but it works, and the stupid quips at the end always make me chuckle.</p>
